{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJECT DESCRIPTION:- We are going to perform machine learning algorithm on iris datasets to classify three different type of species (\"setosa\" as 0, \"versicolor\" as 1, \"verginica\" as 2).In this datsets there are four features sepal length,sepal width,petal length,petal width.This is supervised learning algorithm because output is given along the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:- Loading the iris datasets into the scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the load_iris function in iris object\n",
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\NEHAL-PC\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"target_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "#There are 150 rows and 4 column in the given datasets\n",
    "print(iris[\"data\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a pandas data frame using pandas library it will organise the data in better manner.\n",
    "df_iris=pd.DataFrame(np.c_[iris[\"data\"],iris[\"target\"]],columns = np.append(iris[\"feature_names\"],\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "5                  5.4               3.9                1.7               0.4   \n",
       "6                  4.6               3.4                1.4               0.3   \n",
       "7                  5.0               3.4                1.5               0.2   \n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "16                 5.4               3.9                1.3               0.4   \n",
       "17                 5.1               3.5                1.4               0.3   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "19                 5.1               3.8                1.5               0.3   \n",
       "20                 5.4               3.4                1.7               0.2   \n",
       "21                 5.1               3.7                1.5               0.4   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "23                 5.1               3.3                1.7               0.5   \n",
       "24                 4.8               3.4                1.9               0.2   \n",
       "25                 5.0               3.0                1.6               0.2   \n",
       "26                 5.0               3.4                1.6               0.4   \n",
       "27                 5.2               3.5                1.5               0.2   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "29                 4.7               3.2                1.6               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "121                5.6               2.8                4.9               2.0   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "125                7.2               3.2                6.0               1.8   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "127                6.1               3.0                4.9               1.8   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "129                7.2               3.0                5.8               1.6   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       0.0  \n",
       "10      0.0  \n",
       "11      0.0  \n",
       "12      0.0  \n",
       "13      0.0  \n",
       "14      0.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  \n",
       "22      0.0  \n",
       "23      0.0  \n",
       "24      0.0  \n",
       "25      0.0  \n",
       "26      0.0  \n",
       "27      0.0  \n",
       "28      0.0  \n",
       "29      0.0  \n",
       "..      ...  \n",
       "120     2.0  \n",
       "121     2.0  \n",
       "122     2.0  \n",
       "123     2.0  \n",
       "124     2.0  \n",
       "125     2.0  \n",
       "126     2.0  \n",
       "127     2.0  \n",
       "128     2.0  \n",
       "129     2.0  \n",
       "130     2.0  \n",
       "131     2.0  \n",
       "132     2.0  \n",
       "133     2.0  \n",
       "134     2.0  \n",
       "135     2.0  \n",
       "136     2.0  \n",
       "137     2.0  \n",
       "138     2.0  \n",
       "139     2.0  \n",
       "140     2.0  \n",
       "141     2.0  \n",
       "142     2.0  \n",
       "143     2.0  \n",
       "144     2.0  \n",
       "145     2.0  \n",
       "146     2.0  \n",
       "147     2.0  \n",
       "148     2.0  \n",
       "149     2.0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "145     2.0  \n",
       "146     2.0  \n",
       "147     2.0  \n",
       "148     2.0  \n",
       "149     2.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2 Model Training(finding the solution of our problem that which model is best suited for our problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n"
     ]
    }
   ],
   "source": [
    "#Seperating the feature column from the df_iris data\n",
    "x=df_iris.drop(\"target\",axis=1)\n",
    "print(x.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145    2.0\n",
      "146    2.0\n",
      "147    2.0\n",
      "148    2.0\n",
      "149    2.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y=df_iris[\"target\"]\n",
    "print(y.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing data so that model is trained on different set of data and test on different set of data\n",
    "#the main aim of train and test split to fit the model for outofsample data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "6                  4.6               3.4                1.4               0.3\n",
      "88                 5.6               3.0                4.1               1.3\n",
      "39                 5.1               3.4                1.5               0.2\n",
      "74                 6.4               2.9                4.3               1.3\n",
      "112                6.8               3.0                5.5               2.1\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "128                6.4               2.8                5.6               2.1\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "130                7.4               2.8                6.1               1.9\n",
      "105                7.6               3.0                6.6               2.1\n",
      "107                7.3               2.9                6.3               1.8\n"
     ]
    }
   ],
   "source": [
    "print(x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      0.0\n",
      "88     1.0\n",
      "39     0.0\n",
      "74     1.0\n",
      "112    2.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128    2.0\n",
      "18     0.0\n",
      "130    2.0\n",
      "105    2.0\n",
      "107    2.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will use KNN classifier for our problem\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In knn we have to choose the k value which gives the best result for that we will run the below code for k=1 to k=25 and we will plot the best result using the matplotlib\n",
    "scores=[]\n",
    "for k in range(1,26):\n",
    "    knn=KNeighborsClassifier(k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_predict=knn.predict(x_test)\n",
    "    scores.append(metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we will from the scores against the k value using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "k=range(1,26)\n",
    "plt.plot(k,scores)\n",
    "plt.xlabel(\"K_scores\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we can see in the above graph that from k=5 to k=17 the accuracy is high so we will choose the value in between 5 to 17\n",
    "knn=KNeighborsClassifier(n_neighbors=7)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model of KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 2., 2., 2., 1., 2., 0., 0., 2., 0., 0., 0., 1., 2., 0., 1.,\n",
       "       0., 0., 2., 0., 2., 1., 0., 0., 0., 0., 0., 0., 2., 1., 0., 2., 0.,\n",
       "       1., 2., 2., 1., 1., 0., 2., 0., 1., 0., 2., 0., 0., 1., 1., 2., 0.,\n",
       "       1., 2., 2., 1., 1., 0., 1., 2., 1.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "#checking the accuracy of model\n",
    "print(metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEHAL-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\NEHAL-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model of Logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 2., 2., 2., 1., 2., 0., 0., 1., 0., 0., 0., 1., 2., 0., 1.,\n",
       "       0., 0., 2., 0., 2., 1., 0., 0., 0., 0., 0., 0., 2., 2., 0., 2., 0.,\n",
       "       1., 2., 2., 1., 1., 0., 2., 0., 1., 0., 2., 0., 0., 1., 1., 2., 0.,\n",
       "       1., 2., 2., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two different model one is KNN and other one is Logistic regressor and also successfully tested the model for out of sample dataset,KNN was able to correctly classified  98% accurate while Logistic regressor was 93% accuarate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
